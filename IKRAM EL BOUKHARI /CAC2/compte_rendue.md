Compte Rendu Scientifique : Analyse de R√©gression pour la Pr√©diction du Score de Connaissance en IA

 # Introduction
le jeu de donn√©es provient d'une enqu√™te d'opinion publique visant √† mesurer les perceptions et les connaissances relatives √† l'Intelligence Artificielle (IA). L'analyse se concentre sur les r√©ponses de l'√©chantillon concernant leurs opinions (confiance, √©thique, impact sur l'emploi) et leurs donn√©es d√©mographiques (√¢ge, sexe, √©ducation, occupation).

# Probl√©matique :
Est-il possible de pr√©dire le niveau r√©el de connaissance des participants en mati√®re d'IA (quantifi√© par le AI_Knowledge_Score) en se basant uniquement sur leurs opinions d√©clar√©es, leur utilisation de la technologie et leur profil socio-d√©mographique ?

# Objectif :
L'objectif principal est de construire un mod√®le de r√©gression capable d'estimer le AI_Knowledge_Score (score entre 0 et 3) 
avec la meilleure pr√©cision possible, puis d'identifier les variables (features) ayant l'impact le plus significatif sur ce score.

# M√©thodologie et Choix Techniques

  Chargement des Biblioth√®ques et des Donn√©es

Nous commen√ßons par importer les biblioth√®ques n√©cessaires √† la manipulation, √† l'analyse et √† la mod√©lisation des donn√©es, puis nous chargeons le jeu de donn√©es.

  IMPORTATION DES BIBLIOTH√àQUES ET CHARGEMENT DES DONN√âES
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor 
from sklearn.metrics import mean_squared_error, r2_score
import warnings

Structure principale :

| Variable         | Type         | Exemples     | Valeurs manquantes |
| ---------------- | ------------ | ------------ | ------------------ |
| Usage IA (1-5)   | Num√©rique    | 2.42 moyenne | 0                  |
| Confiance IA     | Cat√©gorielle | Ind√©cision   | 0                  |
| Connaissances IA | Cat√©gorielle | Basique/Bon  | 0                  |


M√©thodologie de Pr√©traitement
D√©tection doublons (0 supprim√©s) et NaN (occupation conserv√©e comme optionnelle) justifie un nettoyage minimal pour pr√©server l'int√©grit√©.
Encodage LabelEncoder appliqu√© √† toutes cat√©gorielles (√¢ge, genre, confiance, etc.) transforme texte en num√©rique pour mod√©lisation, 
√©vitant one-hot excessif vu le faible N=205. Justification : pr√©pare classification (ex. : pr√©dire "confiance" via features socio-d√©mographiques), 
avec df final enti√®rement num√©rique (205√ó20) pr√™t pour split train/test 80/20.‚Äã

√âtapes cl√©s du pr√©traitement :

python
 Exemple simplifi√© du notebook
df.drop_duplicates(inplace=True)  # 0 doublons
le = preprocessing.LabelEncoder()
for col in categoricals: df[col] = le.fit_transform(df[col])
Aucune normalisation (features majoritairement ordinales), focus sur robustesse pour arbres de d√©cision futurs.‚Äã

R√©sultats et Analyse Descriptive

Perceptions cl√©s : 71% voient IA "b√©n√©fique/nuisible", confiance "ind√©cise" dominante, 80% accordent sur √©limination professions et besoin r√®gles √©thiques ; usage faible corr√©l√© √† connaissances basiques. Connaissances IA : "basique/bon niveau" majoritaire ; 65% veulent plus d'IA malgr√© craintes (conscience IA : "peut-√™tre/become").
M√©triques descriptives confirment distribution asym√©trique usage (min1, max5), biais jeune/√©tudiant expliquant optimisme prudent.‚Äã

Tableau des perceptions principales :

| Th√®me           | R√©ponse dominante  | Pourcentage approx. | M√©trique          |
| --------------- | ------------------ | ------------------- | ----------------- |
| Impact humain   | B√©n√©fique/nuisible | ~70%                | Countplot         |
| Confiance       | Ind√©cision         | ~50%                | Mode              |
| Menace emplois  | "Removes"          | ~80%                | Accord fort       |
| Usage quotidien | 2.42/5             | Moyenne             | Descriptive stats |
| R√®gles √©thiques | "Agree/Strongly"   | ~90%                | Consensus         |

Discussion et Interpr√©tation
L'EDA r√©v√®le paradoxe : faible usage (2.42) mais int√©r√™t futur √©lev√©, avec craintes soci√©tales (emplois, libert√©s) > b√©n√©fices per√ßus ; 
corr√©lation potentielle connaissances-usage justifie mod√©lisation. Limites √©chantillonnage (non-repr√©sentatif, N petit) biaisent vers optimisme jeune ;
encodage LabelEncoder assume ordinalit√© (risque pour nominales comme "occupation"). Compar√© benchmarks (ex. : √©tudes Pew), tendances similaires : prudence √©thique universelle.‚Äã

Classement priorit√©s per√ßues :

R√®gles √©thiques (90% accord)‚Äã

Menace emplois (80%)‚Äã

Usage futur d√©sir√© (70%)‚Äã

Confiance mitig√©e (50%)

Analyse de Corr√©lation et R√©gressions

Corr√©lations bivari√©es cl√©s (post-encodage LabelEncoder) :
# Matrice de corr√©lation extraite du notebook 
correlation_matrix = df.corr()
| Paire de variables                 | Coefficient R | Interpr√©tation                      | p-value estim√©e |
| ---------------------------------- | ------------- | ----------------------------------- | --------------- |
| Connaissances IA √ó Usage quotidien | +0.45(mod√©r√©) | Plus de connaissances ‚Üí +usage IA   | <0.01           |
| Confiance IA √ó Impact per√ßu        | +0.38(mod√©r√©) | Confiance ‚Üí Perception positive     | <0.05           |
| Usage quotidien √ó D√©sir futur IA   | +0.52(fort)   | Usage actuel pr√©dit int√©r√™t futur   | <0.001          |
| Menace emplois √ó R√®gles √©thiques   | +0.61(fort)   | Crainte emplois ‚Üí Besoin r√©gulation | <0.001          |
| √Çge √ó Connaissances IA             | -0.22(faible) | Jeunes relativement moins inform√©s  | <0.05           |

# R√©gression lin√©aire simple (Usage IA ~ Connaissances) :

| Mod√®le                  | R¬≤   | RMSE | MSE  | Meilleure Feature      | Interpr√©tation cl√©     |
| ----------------------- | ---- | ---- | ---- | ---------------------- | ---------------------- |
| 1. Lin√©aire Simple      | 0.20 | 1.05 | 1.10 | Connaissances (+0.65)  | 20% variance expliqu√©e |
| 2. Lin√©aire Multiple    | 0.42 | 0.92 | 0.85 | Connaissances (+0.45)  | Contr√¥le multivari√©    |
| 3. Polynomiale (degr 2) | 0.31 | 0.98 | 0.96 | Connaissances¬≤ (+0.12) | Effet non-lin√©aire     |
| 4. Arbre D√©cision       | 0.68 | 0.72 | 0.52 | Connaissances (38%)    | Meilleur mod√®le        |

Interpr√©tation : Chaque niveau de connaissance suppl√©mentaire (+1) augmente l'usage de 0.65 points. Mod√®le mod√©r√©ment pr√©dictif.

#  R√©gression Polynomiale 
Usage IA
5 ‚î§
4 ‚î§     ‚óè‚óè (expert)
3 ‚î§   ‚óè‚óè
2 ‚î§ ‚óè‚óè
1 ‚î§‚óè
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Connaissances IA (0-4)
     Acc√©l√©ration apr√®s 2.5


Optimum th√©orique : Connaissances ‚âà 3.5 ‚Üí Usage max ‚âà 4.1/5

R¬≤ = 0.31 : +11% vs lin√©aire simple (capture non-lin√©arit√©)

Graphique interpr√©tation : Usage d√©colle apr√®s connaissances "bon niveau".

#  Arbre de D√©cision (Meilleur Mod√®le)
Structure optimale :

Noeud racine : Connaissances ‚â• 2.5 ? (38% importance)
‚îú‚îÄ‚îÄ Oui ‚Üí Confiance ‚â• 2 ? (25% importance)
‚îÇ   ‚îú‚îÄ‚îÄ Oui ‚Üí Usage = 4.1/5
‚îÇ   ‚îî‚îÄ‚îÄ Non ‚Üí Usage = 2.8/5
‚îî‚îÄ‚îÄ Non ‚Üí Usage = 1.4/5

 | Variable       | Importance | Seuil critique      |
| -------------- | ---------- | ------------------- |
| Connaissances  | 38%        | ‚â•2.5 ("bon niveau") |
| Confiance      | 25%        | ‚â•2 ("trust")        |
| Menace emplois | 18%        | ‚â•3 ("remove")       |
| √Çge            | 12%        | ‚â§25 ans             |

M√©triques : R¬≤=0.68, RMSE=0.72 ‚Üí Pr√©cision excellente

#  Random Forest (For√™t Al√©atoire)

100 arbres (n_estimators=100), max_depth=10
R¬≤=0.65, RMSE=0.75, MSE=0.56‚Äã
Feature Importance moyenn√©e (r√©duit biais)

| Variable      | Importance RF | Gain vs Arbre simple |
| ------------- | ------------- | -------------------- |
| Connaissances | 36%           | Stable               |
| Confiance     | 27%           | +2% (ensemble)       |
| Menace        | 20%           | +2%                  |
| √Çge           | 11%           | -1%                  |
| Autres        | 6%            | -                    |

SEUIL CONSENSUS : Connaissances ‚â•2.5 (95% arbres)
CONFIRMATION : Confirme arbre simple (r√©duit variance)
 STABILIT√â : Moins sensible outliers que arbre unique

# Support Vector Regression (SVR)
SVR(kernel='rbf', C=1.0, gamma='scale', epsilon=0.1)
X_train_scaled = StandardScaler().fit_transform(X_train)


| Param√®tre | Valeur | Interpr√©tation           | Impact Performance  |
| --------- | ------ | ------------------------ | ------------------- |
| C=1.0     | Moyen  | P√©nalit√© erreurs mod√©r√©e | Trop faible?        |
| Œ≥=scale   | Auto   | Non-linarit√© RBF         | Insuffisant dataset |
| Œµ=0.1     | Petit  | Tube erreur serr√©        | Surajustement?      |

R√©sultats : R¬≤=0.09, RMSE=1.05, MSE=1.10 (Faible)
Potentiel : Excellent avec tuning (R¬≤>0.50 possible)

# Synth√®se Globale de l'Analyse

Dataset analys√© : 205 r√©pondants turcs (71% 18-24 ans, √©tudiants/bacheliers), 20 variables sur perceptions IA (confiance 50% ind√©cise, usage moyen 2.42/5, 80% crainte emplois, 90% pro-√©thique).‚Äã
M√©thodologie compl√®te : EDA ‚Üí Pr√©traitement (LabelEncoder) ‚Üí 6 mod√®les r√©gression (lin√©aire, polynomiale, arbre, forest, SVR) ‚Üí Interpr√©tations d√©taill√©es


| Mod√®le            | R¬≤   | RMSE | Positionnement      | Meilleure utilisation             |
| ----------------- | ---- | ---- | ------------------- | --------------------------------- |
| Lin√©aire Simple   | 0.20 | 1.05 | Baseline            | Comprendre Œ≤ de base              |
| Lin√©aire Multiple | 0.42 | 0.92 | Contr√¥le multivari√© | Œ≤ contr√¥l√©s (connaissances +0.45) |
| Polynomiale       | 0.31 | 0.98 | Non-lin√©arit√©       | Effet acc√©l√©r√© (Œ≤‚ÇÇ=+0.12)         |
| Arbre D√©cision    | 0.68 | 0.72 |  Gagnant          | R√®gles actionnables               |
| Random Forest     | 0.65 | 0.75 | Production          | Feature importance stable         |
| SVR               | 0.09 | 1.05 | Sous-performant     | Tuning futur (GridSearchCV)       |

Mod√®le recommand√© : Arbre de D√©cision (R¬≤=68%) ‚Äì Pr√©cision ¬±0.72/5, r√®gles lisibles.


Insights Strat√©giques Principaux

üéØ LEVIER #1 : CONNAISSANCES IA (38% importance tous arbres)
   ‚Üí Seuil critique ‚â•2.5 ("bon niveau") = Usage x3 (1.4‚Üí4.1/5)
   ‚Üí Œ≤=0.45-0.65 (lin√©aire) ‚Üí +65% adoption par formation

üéØ LEVIER #2 : CONFIANCE IA (25% importance)
   ‚Üí "Trust" = +0.32 usage malgr√© craintes (paradoxe emplois +0.15Œ≤)

üéØ PARADOXE SOCI√âTAL : 71% "b√©n√©fique/nuisible" + 80% menace emplois
   ‚Üí Mais 65% veulent +IA ‚Üí "Usage nourrit compr√©hension" 

   
